{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8fe90a31-ee5e-4d74-ae70-311f9fe5cc4f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-05T13:49:40.839790Z",
     "iopub.status.busy": "2024-12-05T13:49:40.839478Z",
     "iopub.status.idle": "2024-12-05T13:49:59.380789Z",
     "shell.execute_reply": "2024-12-05T13:49:59.380088Z",
     "shell.execute_reply.started": "2024-12-05T13:49:40.839767Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/dolphinfs/hdd_pool/docker/user/hadoop-dpsr/zhouyang96/conda_env/zy_from_chr_right_right/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Error.  nthreads cannot be larger than environment variable \"NUMEXPR_MAX_THREADS\" (64)2024-12-05 21:49:51.553267: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-12-05 21:49:51.569288: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-12-05 21:49:51.573928: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-12-05 21:49:51.586668: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-12-05 21:49:54.163246: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "from tqdm.auto import tqdm\n",
    "from bs4 import BeautifulSoup\n",
    "import gc\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import sys\n",
    "import numpy as np\n",
    "from tqdm.autonotebook import trange\n",
    "from sklearn.model_selection import GroupKFold\n",
    "import json\n",
    "import torch\n",
    "from numpy.linalg import norm\n",
    "import torch.nn.functional as F\n",
    "from torch import Tensor\n",
    "from transformers import AutoTokenizer, AutoModel,BitsAndBytesConfig\n",
    "from peft import (\n",
    "    LoraConfig,\n",
    "    get_peft_model,\n",
    ")\n",
    "import json\n",
    "import copy\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "def apk(actual, predicted, k=25):\n",
    "    \"\"\"\n",
    "    Computes the average precision at k.\n",
    "    \n",
    "    This function computes the average prescision at k between two lists of\n",
    "    items.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    actual : list\n",
    "             A list of elements that are to be predicted (order doesn't matter)\n",
    "    predicted : list\n",
    "                A list of predicted elements (order does matter)\n",
    "    k : int, optional\n",
    "        The maximum number of predicted elements\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    score : double\n",
    "            The average precision at k over the input lists\n",
    "    \"\"\"\n",
    "    \n",
    "    if not actual:\n",
    "        return 0.0\n",
    "\n",
    "    if len(predicted)>k:\n",
    "        predicted = predicted[:k]\n",
    "\n",
    "    score = 0.0\n",
    "    num_hits = 0.0\n",
    "\n",
    "    for i,p in enumerate(predicted):\n",
    "        # first condition checks whether it is valid prediction\n",
    "        # second condition checks if prediction is not repeated\n",
    "        if p in actual and p not in predicted[:i]:\n",
    "            num_hits += 1.0\n",
    "            score += num_hits / (i+1.0)\n",
    "\n",
    "    return score / min(len(actual), k)\n",
    "\n",
    "def mapk(actual, predicted, k=25):\n",
    "    \"\"\"\n",
    "    Computes the mean average precision at k.\n",
    "    \n",
    "    This function computes the mean average prescision at k between two lists\n",
    "    of lists of items.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    actual : list\n",
    "             A list of lists of elements that are to be predicted \n",
    "             (order doesn't matter in the lists)\n",
    "    predicted : list\n",
    "                A list of lists of predicted elements\n",
    "                (order matters in the lists)\n",
    "    k : int, optional\n",
    "        The maximum number of predicted elements\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    score : double\n",
    "            The mean average precision at k over the input lists\n",
    "    \"\"\"\n",
    "    \n",
    "    return np.mean([apk(a,p,k) for a,p in zip(actual, predicted)])\n",
    "\n",
    "def batch_to_device(batch, target_device):\n",
    "    \"\"\"\n",
    "    send a pytorch batch to a device (CPU/GPU)\n",
    "    \"\"\"\n",
    "    for key in batch:\n",
    "        if isinstance(batch[key], Tensor):\n",
    "            batch[key] = batch[key].to(target_device)\n",
    "    return batch\n",
    "\n",
    "def last_token_pool(last_hidden_states: Tensor,\n",
    "                    attention_mask: Tensor) -> Tensor:\n",
    "    left_padding = (attention_mask[:, -1].sum() == attention_mask.shape[0])\n",
    "    if left_padding:\n",
    "        return last_hidden_states[:, -1]\n",
    "    else:\n",
    "        sequence_lengths = attention_mask.sum(dim=1) - 1\n",
    "        batch_size = last_hidden_states.shape[0]\n",
    "        return last_hidden_states[torch.arange(batch_size, device=last_hidden_states.device), sequence_lengths]\n",
    "\n",
    "def get_detailed_instruct(task_description: str, query: str) -> str:\n",
    "    return f'Instruct: {task_description}\\nQuery: {query}'\n",
    "\n",
    "def inference(df, model, tokenizer, device):\n",
    "    batch_size = 32\n",
    "    max_length = 512\n",
    "    sentences = list(df['query_text'].values)\n",
    "    pids = list(df['order_index'].values)\n",
    "    all_embeddings = []\n",
    "    length_sorted_idx = np.argsort([-len(sen) for sen in sentences])\n",
    "    sentences_sorted = [sentences[idx] for idx in length_sorted_idx]\n",
    "    for start_index in trange(0, len(sentences), batch_size, desc=\"Batches\", disable=False):\n",
    "        sentences_batch = sentences_sorted[start_index: start_index + batch_size]\n",
    "        features = tokenizer(sentences_batch, max_length=max_length, padding=True, truncation=True,\n",
    "                             return_tensors=\"pt\")\n",
    "        features = batch_to_device(features, device)\n",
    "        with torch.no_grad():\n",
    "            outputs = model.model(**features)\n",
    "            embeddings = last_token_pool(outputs.last_hidden_state, features['attention_mask'])\n",
    "            embeddings = torch.nn.functional.normalize(embeddings, dim=-1)\n",
    "            embeddings = embeddings.detach().cpu().numpy().tolist()\n",
    "        all_embeddings.extend(embeddings)\n",
    "\n",
    "    all_embeddings = [np.array(all_embeddings[idx]).reshape(1, -1) for idx in np.argsort(length_sorted_idx)]\n",
    "\n",
    "    sentence_embeddings = np.concatenate(all_embeddings, axis=0)\n",
    "    result = {pids[i]: em for i, em in enumerate(sentence_embeddings)}\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b0e641c8-501d-467f-9460-0a42aef7e8a5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-05T13:49:59.382460Z",
     "iopub.status.busy": "2024-12-05T13:49:59.381932Z",
     "iopub.status.idle": "2024-12-05T13:49:59.385454Z",
     "shell.execute_reply": "2024-12-05T13:49:59.384936Z",
     "shell.execute_reply.started": "2024-12-05T13:49:59.382439Z"
    }
   },
   "outputs": [],
   "source": [
    "path_prefix = \"../data\"\n",
    "# model_path=\"/mnt/dolphinfs/hdd_pool/docker/user/hadoop-dpsr/zhouyang96/zy_model_path/SFR-Embedding-2_R\"\n",
    "# model_path=\"/mnt/dolphinfs/hdd_pool/docker/user/hadoop-dpsr/model_path/Qwen2___5-72B-Instruct\"\n",
    "# model_path=\"/mnt/dolphinfs/hdd_pool/docker/user/hadoop-dpsr/model_path/Qwen2___5-Math-72B-Instruct\"\n",
    "model_path=\"./Qwen2___5-14B-Instruct\"\n",
    "lora_path=\"./simcse_qwen25_72b_recall_v9_gen_step2_72b_5e-5_load/epoch_19_model/adapter.bin\"\n",
    "device='cuda:0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "847ccb19-68c7-4509-875b-8192af00e44b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-05T13:49:59.386239Z",
     "iopub.status.busy": "2024-12-05T13:49:59.386069Z",
     "iopub.status.idle": "2024-12-05T13:49:59.493793Z",
     "shell.execute_reply": "2024-12-05T13:49:59.493238Z",
     "shell.execute_reply.started": "2024-12-05T13:49:59.386224Z"
    }
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv(f\"{path_prefix}/train.csv\")\n",
    "test = pd.read_csv(f\"{path_prefix}/test.csv\")\n",
    "sample_submission = pd.read_csv(f\"{path_prefix}/sample_submission.csv\")\n",
    "misconception_mapping = pd.read_csv(f\"{path_prefix}/misconception_mapping.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b2456c0-7b25-4414-83b2-d4c07c120a19",
   "metadata": {},
   "source": [
    "# load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "33fb1da0-d1e5-4af0-89be-e32a9ecf53ef",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-18T14:30:53.614569Z",
     "iopub.status.busy": "2024-11-18T14:30:53.614401Z",
     "iopub.status.idle": "2024-11-18T14:31:12.870803Z",
     "shell.execute_reply": "2024-11-18T14:31:12.869855Z",
     "shell.execute_reply.started": "2024-11-18T14:30:53.614554Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 8/8 [00:11<00:00,  1.43s/it]\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "# model = AutoModel.from_pretrained(model_path)\n",
    "if lora_path!=\"\":\n",
    "    bnb_config = BitsAndBytesConfig(\n",
    "                load_in_4bit=True,\n",
    "                bnb_4bit_use_double_quant=True,\n",
    "                bnb_4bit_quant_type=\"nf4\",\n",
    "                bnb_4bit_compute_dtype=torch.bfloat16\n",
    "            )\n",
    "    model = AutoModel.from_pretrained(model_path, quantization_config=bnb_config,device_map=device)\n",
    "    config = LoraConfig(\n",
    "            r=64,\n",
    "            lora_alpha=128,\n",
    "            target_modules=[\n",
    "                \"q_proj\",\n",
    "                \"k_proj\",\n",
    "                \"v_proj\",\n",
    "                \"o_proj\",\n",
    "                \"gate_proj\",\n",
    "                \"up_proj\",\n",
    "                \"down_proj\",\n",
    "            ],\n",
    "            bias=\"none\",\n",
    "            lora_dropout=0.05,  # Conventional\n",
    "            task_type=\"CAUSAL_LM\",\n",
    "        )\n",
    "    model = get_peft_model(model, config)\n",
    "    # if lora_path\n",
    "    d = torch.load(lora_path, map_location=model.device)\n",
    "    model.load_state_dict(d, strict=False)\n",
    "else:\n",
    "    model = AutoModel.from_pretrained(model_path)\n",
    "    model = model.to(torch.float16)\n",
    "    \n",
    "model = model.eval()\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e5b6f5d-e498-4306-9c94-dd4096ac9480",
   "metadata": {},
   "source": [
    "# 划分数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2f2ad355-e6d8-4603-b28e-3483225b2272",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-18T14:31:12.872172Z",
     "iopub.status.busy": "2024-11-18T14:31:12.871882Z",
     "iopub.status.idle": "2024-11-18T14:31:12.885261Z",
     "shell.execute_reply": "2024-11-18T14:31:12.884751Z",
     "shell.execute_reply.started": "2024-11-18T14:31:12.872152Z"
    }
   },
   "outputs": [],
   "source": [
    "groups = train['QuestionId'].values\n",
    "# 创建 GroupKFold 对象\n",
    "group_kfold = GroupKFold(n_splits=5)\n",
    "train = train.reset_index(drop=True)\n",
    "# 进行分组交叉验证\n",
    "for train_index, test_index in group_kfold.split(train, groups=groups):\n",
    "    tra = train.iloc[train_index,:]\n",
    "    tra['is_train']=True\n",
    "    val = train.iloc[test_index,:]\n",
    "    val['is_train']=False\n",
    "    # tra = val\n",
    "    break\n",
    "tra = pd.concat([tra,val],axis=0)\n",
    "# tra.shape,val.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3caef749-a944-413b-8912-1b0a8ffee5c4",
   "metadata": {},
   "source": [
    "# 获得query embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "69d9035b-802b-4d38-805a-09c5787a53df",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-18T14:31:12.886294Z",
     "iopub.status.busy": "2024-11-18T14:31:12.885908Z",
     "iopub.status.idle": "2024-11-18T14:31:12.888536Z",
     "shell.execute_reply": "2024-11-18T14:31:12.888066Z",
     "shell.execute_reply.started": "2024-11-18T14:31:12.886277Z"
    }
   },
   "outputs": [],
   "source": [
    "task_description = 'Given a math question and a misconcepte incorrect answer, please retrieve the most accurate reason for the misconception.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "36f7aa46-7ad1-4a30-baae-ff041e328392",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-18T14:31:12.889469Z",
     "iopub.status.busy": "2024-11-18T14:31:12.889146Z",
     "iopub.status.idle": "2024-11-18T14:31:12.894310Z",
     "shell.execute_reply": "2024-11-18T14:31:12.893816Z",
     "shell.execute_reply.started": "2024-11-18T14:31:12.889453Z"
    }
   },
   "outputs": [],
   "source": [
    "tra = pd.read_parquet(\"../create_data/save_data/cv1.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "64e32502-5056-454b-a47e-b47ac31ec295",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-18T14:31:12.895083Z",
     "iopub.status.busy": "2024-11-18T14:31:12.894923Z",
     "iopub.status.idle": "2024-11-18T14:31:12.900195Z",
     "shell.execute_reply": "2024-11-18T14:31:12.899742Z",
     "shell.execute_reply.started": "2024-11-18T14:31:12.895068Z"
    }
   },
   "outputs": [],
   "source": [
    "train_data = []\n",
    "for _,row in tra.iterrows():\n",
    "    real_text = row['CorrectAnswer'].split('.',1)[-1]\n",
    "    SelectedAnswer = row['SelectedAnswer'].split('.',1)[-1]\n",
    "    query_text =f\"###question###:{row['SubjectName']}-{row['ConstructName']}-{row['Question']}\\n###Correct Answer###:{real_text}\\n###Misconcepte Incorrect answer###:{SelectedAnswer}\"\n",
    "    row['query_text'] = get_detailed_instruct(task_description,query_text)\n",
    "    query_text2 = f\"###question###:{row['SubjectName']}-{row['ConstructName']}-{row['Question']}\\n###Correct Answer###:{real_text}\\n###Incorrect distractor answer###:{SelectedAnswer}\"\n",
    "    row['answer_id'] = row['mis_id']\n",
    "    train_data.append(copy.deepcopy(row))\n",
    "train_df = pd.DataFrame(train_data)\n",
    "train_df['order_index'] = list(range(len(train_df)))\n",
    "train_df['is_train'] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b5cab8dd-9941-4eac-9ac7-2cb10ac578d2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-18T14:35:34.792260Z",
     "iopub.status.busy": "2024-11-18T14:35:34.791659Z",
     "iopub.status.idle": "2024-11-18T14:35:34.810591Z",
     "shell.execute_reply": "2024-11-18T14:35:34.809920Z",
     "shell.execute_reply.started": "2024-11-18T14:35:34.792239Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    4370.000000\n",
       "mean       69.664760\n",
       "std        29.507826\n",
       "min        34.000000\n",
       "25%        49.000000\n",
       "50%        61.000000\n",
       "75%        82.000000\n",
       "max       300.000000\n",
       "Name: query_text, dtype: float64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df['query_text'].apply(lambda x: len(x.split(' '))).describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a40fbe6-e365-4bd7-a216-6f50cf1e92e1",
   "metadata": {},
   "source": [
    "# 推理query embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1005790b-754c-4879-9efd-2cfc0bf8fa78",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-18T14:35:36.443934Z",
     "iopub.status.busy": "2024-11-18T14:35:36.443562Z",
     "iopub.status.idle": "2024-11-18T14:38:35.402052Z",
     "shell.execute_reply": "2024-11-18T14:38:35.401081Z",
     "shell.execute_reply.started": "2024-11-18T14:35:36.443915Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 137/137 [02:57<00:00,  1.30s/it]\n"
     ]
    }
   ],
   "source": [
    "train_embeddings = inference(train_df, model, tokenizer, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a40a8a68-e118-41d0-a51f-22401997944d",
   "metadata": {},
   "source": [
    "# 获得answer 的embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8a22f648-dcab-4e95-9624-4d2fd4ebb915",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-18T14:38:35.403732Z",
     "iopub.status.busy": "2024-11-18T14:38:35.403367Z",
     "iopub.status.idle": "2024-11-18T14:39:01.181818Z",
     "shell.execute_reply": "2024-11-18T14:39:01.180654Z",
     "shell.execute_reply.started": "2024-11-18T14:38:35.403710Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 81/81 [00:24<00:00,  3.25it/s]\n"
     ]
    }
   ],
   "source": [
    "misconception_mapping['query_text'] = misconception_mapping['MisconceptionName']\n",
    "misconception_mapping['order_index'] = misconception_mapping['MisconceptionId']\n",
    "doc_embeddings = inference(misconception_mapping, model, tokenizer, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "73b2812d-0a2f-409a-ac71-03dac747aff8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-18T14:39:01.183150Z",
     "iopub.status.busy": "2024-11-18T14:39:01.182915Z",
     "iopub.status.idle": "2024-11-18T14:39:01.241086Z",
     "shell.execute_reply": "2024-11-18T14:39:01.240386Z",
     "shell.execute_reply.started": "2024-11-18T14:39:01.183127Z"
    }
   },
   "outputs": [],
   "source": [
    "sentence_embeddings = np.concatenate([e.reshape(1, -1) for e in list(doc_embeddings.values())])\n",
    "index_text_embeddings_index = {index: paper_id for index, paper_id in\n",
    "                                         enumerate(list(doc_embeddings.keys()))}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc19d0ea-733a-4413-b287-0d834562c9a1",
   "metadata": {},
   "source": [
    "# 召回文本topn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "66e29a87-e2bf-4f0a-8749-c4696f5f620e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-18T14:39:01.242818Z",
     "iopub.status.busy": "2024-11-18T14:39:01.242528Z",
     "iopub.status.idle": "2024-11-18T14:39:03.580088Z",
     "shell.execute_reply": "2024-11-18T14:39:03.578859Z",
     "shell.execute_reply.started": "2024-11-18T14:39:01.242799Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4370it [00:02, 1875.57it/s]\n"
     ]
    }
   ],
   "source": [
    "predicts_test = []\n",
    "for _, row in tqdm(train_df.iterrows()):\n",
    "    query_id = row['order_index']\n",
    "    query_em = train_embeddings[query_id].reshape(1, -1)\n",
    "    \n",
    "    # 计算点积\n",
    "    cosine_similarity = np.dot(query_em, sentence_embeddings.T).flatten()\n",
    "    # 对余弦相似度进行排序并获取前100个索引\n",
    "    sort_index = np.argsort(-cosine_similarity)[:150]\n",
    "    # for index in sort_index[:4]:\n",
    "    #     print(cosine_similarity[index])\n",
    "    # print(\"*\"*20)\n",
    "    pids = [index_text_embeddings_index[index] for index in sort_index]\n",
    "    predicts_test.append(pids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "95d0c6cd-4d33-4ad6-b4e7-0a0699181832",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-18T14:39:03.581855Z",
     "iopub.status.busy": "2024-11-18T14:39:03.581461Z",
     "iopub.status.idle": "2024-11-18T14:39:03.587905Z",
     "shell.execute_reply": "2024-11-18T14:39:03.587111Z",
     "shell.execute_reply.started": "2024-11-18T14:39:03.581823Z"
    }
   },
   "outputs": [],
   "source": [
    "train_df['recall_ids'] = predicts_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "fd34d04a-cbc8-4020-bd8e-5ff31662b414",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-18T14:39:03.589321Z",
     "iopub.status.busy": "2024-11-18T14:39:03.588893Z",
     "iopub.status.idle": "2024-11-18T14:39:03.607984Z",
     "shell.execute_reply": "2024-11-18T14:39:03.607230Z",
     "shell.execute_reply.started": "2024-11-18T14:39:03.589291Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5801454503126756"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mapk([[data] for data in train_df[train_df['is_train']==False]['answer_id'].values],train_df[train_df['is_train']==False]['recall_ids'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a7397c0e-cf50-45d9-a251-9c86efe830fe",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-18T14:39:03.609329Z",
     "iopub.status.busy": "2024-11-18T14:39:03.608916Z",
     "iopub.status.idle": "2024-11-18T14:39:03.613719Z",
     "shell.execute_reply": "2024-11-18T14:39:03.612994Z",
     "shell.execute_reply.started": "2024-11-18T14:39:03.609302Z"
    }
   },
   "outputs": [],
   "source": [
    "def recall_score(reals,recalls,k=25):\n",
    "    res = 0.\n",
    "    for i in range(len(reals)):\n",
    "        real = reals[i][0]\n",
    "        for c in recalls[i][:k]:\n",
    "            if c==real:\n",
    "                res+=1\n",
    "                break\n",
    "    return res/len(reals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "473865a2-6a71-498a-a42d-599b70cdf8eb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-18T14:39:03.615041Z",
     "iopub.status.busy": "2024-11-18T14:39:03.614647Z",
     "iopub.status.idle": "2024-11-18T14:39:03.629808Z",
     "shell.execute_reply": "2024-11-18T14:39:03.629094Z",
     "shell.execute_reply.started": "2024-11-18T14:39:03.615014Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.931554524361949"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall_score([[data] for data in train_df[train_df['is_train']==False]['answer_id'].values],train_df[train_df['is_train']==False]['recall_ids'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c7d31ec0-bd3f-45bf-ab86-7cb4681a1a71",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-18T14:39:03.631049Z",
     "iopub.status.busy": "2024-11-18T14:39:03.630705Z",
     "iopub.status.idle": "2024-11-18T14:39:03.760296Z",
     "shell.execute_reply": "2024-11-18T14:39:03.759784Z",
     "shell.execute_reply.started": "2024-11-18T14:39:03.631021Z"
    }
   },
   "outputs": [],
   "source": [
    "misconception_mapping_dict = {}\n",
    "for _,row in misconception_mapping.iterrows():\n",
    "    misconception_mapping_dict[row['MisconceptionId']] = row['MisconceptionName']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ef054050-ef0e-4b20-b730-0991fa19fe5d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-18T14:39:03.761991Z",
     "iopub.status.busy": "2024-11-18T14:39:03.761674Z",
     "iopub.status.idle": "2024-11-18T14:39:05.277610Z",
     "shell.execute_reply": "2024-11-18T14:39:05.276908Z",
     "shell.execute_reply.started": "2024-11-18T14:39:03.761975Z"
    }
   },
   "outputs": [],
   "source": [
    "# prompt=f\"\"\"Given a math problem and an incorrect answer, please select the most accurate distractor analyses regarding this incorrect answer.\\n{}\"\"\"\n",
    "def save_fun(df,is_test):\n",
    "    df['data_id'] = list(range(len(df)))\n",
    "    save_df = []\n",
    "    for _,row in df.iterrows():\n",
    "        answer_text = misconception_mapping_dict[row['answer_id']]\n",
    "        recall_texts = []\n",
    "        if is_test:\n",
    "            ids = row['recall_ids'][:100]\n",
    "        else:\n",
    "            ids = row['recall_ids'][:100]\n",
    "        recall_ids = []\n",
    "        or_recall_texts = []\n",
    "        for i in ids:\n",
    "            or_recall_texts.append(misconception_mapping_dict[i])\n",
    "            if not is_test and i==row['answer_id']:\n",
    "                continue\n",
    "            recall_ids.append(i)\n",
    "            recall_texts.append(misconception_mapping_dict[i])\n",
    "        save_df.append(\n",
    "            {\n",
    "                \"recall_texts\":recall_texts,\n",
    "                \"recall_ids\":recall_ids,\n",
    "                \"answer_text\":answer_text,\n",
    "                \"prompt\":f\"\"\"Given a math problem and an incorrect distractor answer, please select the most accurate distractor analyses regarding this incorrect distractor answer.\\n{row['query_text2']}\"\"\",\n",
    "                \"data_id\":row['data_id'],\n",
    "                \"answer_id\":row['answer_id'],\n",
    "                \"key\":row['key'],\n",
    "                \"or_recall_ids\":row['recall_ids'],\n",
    "                \"or_recall_texts\":or_recall_texts\n",
    "            }\n",
    "        )\n",
    "    save_df = pd.DataFrame(save_df)\n",
    "    return save_df\n",
    "new_train = save_fun(train_df[train_df['is_train']==True],is_test=False)\n",
    "new_test = save_fun(train_df[train_df['is_train']==False],is_test=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "81d0ecc4-154a-42a9-98f1-3b287a61acfa",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-18T14:39:05.278576Z",
     "iopub.status.busy": "2024-11-18T14:39:05.278335Z",
     "iopub.status.idle": "2024-11-18T14:39:05.282005Z",
     "shell.execute_reply": "2024-11-18T14:39:05.281517Z",
     "shell.execute_reply.started": "2024-11-18T14:39:05.278559Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(862, 9)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0a2b967f-e1a9-4da1-a2c0-5abbd332e3cb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-18T14:39:05.282931Z",
     "iopub.status.busy": "2024-11-18T14:39:05.282597Z",
     "iopub.status.idle": "2024-11-18T14:39:05.288978Z",
     "shell.execute_reply": "2024-11-18T14:39:05.288504Z",
     "shell.execute_reply.started": "2024-11-18T14:39:05.282916Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3508, 9)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "294c9c9c-1307-4807-ae83-c573f38481d3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "881d9e07-467a-4d34-b90f-f84d9ec849cb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-18T14:39:11.513278Z",
     "iopub.status.busy": "2024-11-18T14:39:11.512972Z",
     "iopub.status.idle": "2024-11-18T14:39:11.991200Z",
     "shell.execute_reply": "2024-11-18T14:39:11.990505Z",
     "shell.execute_reply.started": "2024-11-18T14:39:11.513260Z"
    }
   },
   "outputs": [],
   "source": [
    "new_train.to_parquet(\"../train_data/rank_v9_gen_warmup_fintune/train.parquet\")\n",
    "new_test.to_parquet(\"../train_data/rank_v9_gen_warmup_fintune/dev.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a526321-0cf2-4c15-9de0-81863c818597",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98936bbb-841e-4e1b-bdc0-916b6032bf36",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f095c49-4ab0-452a-b02c-2c027a30893a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "zy_right_right",
   "language": "python",
   "name": "zy_right_right"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
